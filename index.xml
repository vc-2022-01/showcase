<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Computación Visual</title><link>https://visualcomputing.github.io/showcase/</link><description>Recent content in Introduction on Computación Visual</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://visualcomputing.github.io/showcase/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://visualcomputing.github.io/showcase/docs/Members/Andr%C3%A9s-Felipe-Betancurth-Becerra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Members/Andr%C3%A9s-Felipe-Betancurth-Becerra/</guid><description>Andrés Felipe Betancurth Becerra # estudiante de decima matricula de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia con lo que es practicamente solo la mitad de avance de mi carrera, me interesa el campo de la inteligencia artificial orientado al maching lerning, las curiosidades y las series.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Members/Gabriela-Mar%C3%ADa-Garc%C3%ADa-Romero/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Members/Gabriela-Mar%C3%ADa-Garc%C3%ADa-Romero/</guid><description> Gabriela María García Romero # Estudiante de octavo semestre de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia. Con interés en temas de modelización e inteligencia artificial. Actualmente se desempeña como representante estudiantil ante el Comité Asesor de la carrea.
Hace parte de los siguientes grupos:
Semillero Laboratorio de Investigación en Sistemas Inteligentes (LISI) WIE (Women in Engineering)</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Members/Juan-Manuel-Correa-Lombana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Members/Juan-Manuel-Correa-Lombana/</guid><description> Juan Manuel Correa Lombana # Estudiante de octavo semestre de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia. , con 1 año de experiencia en manejo de datos y ciencia de datos. Entre sus proyectos realizados se encuentra:
6 meses en un proyecto de grafos y optimización de rutas de transporte usando inteligencia artificial 8 meses como analista de datos y ciencia de datos Actualmente llevo 2 meses en ingeniería de datos en el área de arquitectura de bases de datos</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Perlin-Noise/Particule/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Perlin-Noise/Particule/</guid><description>Movimiento de partículas a través de un campo de perlin noise # En el siguiente frame se puede ver el movimiento con rastro de partículas a través de un campo de perlin noise
si jugamos con la rejilla y la dirección de los vectores, se pueden generar texturas o efectos visuales más complejos
Snow # Grass # Según lo explica Andre Tatarinov en su paper titulado Perlin noise in Real-time Computer Graphics, esto también se puede usar para generar efectos dinámicos volumétricos como fuego, una explosión o humo, esto solo cambiando la dirección y el comportamiento de los vectores asociados a la rejilla.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Perlin-Noise/Terrain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Perlin-Noise/Terrain/</guid><description>Terreno procedural # {{&amp;lt; let terrain = []; function setup() { createCanvas(500, 500, WEBGL); cols = 0;rows = 0; elevacion = 100; scl = 25; vel = 0.05; cambio = scl; crecimiento = 0.07; w = 800; h = 800; cols = w/scl; rows = h/scl; avance = 0; } function stripOfTerrain(){ yoff = avance; xoff = 0; for(x = 0; x &amp;lt; (cols);x++){ terrain[x] = []; } for(y = 0; y &amp;lt; (rows); y++){ xoff = 0; for(x = 0; x &amp;lt; (cols);x++){ terrain[x][y] = map(noise(xoff,yoff),0,1,-elevacion,elevacion); xoff += crecimiento; } yoff += crecimiento; } } function draw() { stripOfTerrain(); cols = w/scl; rows = h/scl; avance -= vel; background(&amp;#39;blue&amp;#39;); stroke(255); rotateX(PI/3); translate(-375,-525); for(y = 0; y &amp;lt; rows; y++){ beginShape(TRIANGLE_STRIP); for(x = 0; x &amp;lt; cols;x++){ fill(10,200,200-terrain[x][y]*10) vertex(x*scl,y*scl,terrain[x][y]); fill(10,255,100-terrain[x][y+1]*10) vertex(x*scl,(y+1)*scl,terrain[x][y+1]); } endShape(); } } &amp;gt;}} All parameters are optional but sketch.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Rendering/1.-Baseline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Rendering/1.-Baseline/</guid><description>Proportionality and symmetry # The key to the illusion realized in the game by forced perception is the proportionality that exists between the field of view and the object. The object grows as much as the field of view. This can be demonstrated by the proportionality theorem for triangles, where the ratio between z&amp;rsquo;/z is equivalent to the ratio between x&amp;rsquo;/x, since they have the same θ the angle of the field of view:</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Rendering/2.-Pixel-Density/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Rendering/2.-Pixel-Density/</guid><description>The world and the pixel # Each pixel on the screen represents a quantity of space in the space of the world. The illusion of forced perspective allows to keep the relation that exists between the world and the pixel, that is to say, the amount of world that can be represented in the pixel in the space of the screen, this relation is going to be called density and is used by the function pixelRatio in the code previously seen.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Rendering/3.-Aplications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Rendering/3.-Aplications/</guid><description>Concept 1 # In the present example an intuitive demonstration of forced perception is made. Two spheres are used which, in perspective, look the same size. However, one of them can be resized in such a way that it changes size in the world, but the camera perceives them as the same size. This happens because of the distance in relation to the camera.
Instructions
Select any of the spheres with a number (0 to 2) Press w or s to zoom in or zoom out on the sphere On the left screen you will see that the spheres do not change size.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Rendering/4.-Conslusions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Rendering/4.-Conslusions/</guid><description>Conclusions # The Superliminal game is made possible by elements of rendering that occur in computer graphics. It is through the process of the rendering pipeline that it is possible to achieve the effect of forced perception on the players. Even though an object changes in the world, because of its location and size in the world, this change is neither perceivable in the camera nor projectable on the screen.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/Color-brightness/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/Color-brightness/</guid><description>Color brightness tools # Ejercicio 2: Texture Sampling # El modelo de color HSV ( Hue, Saturation, Value. Por sus siglas en inglés) también es llamado HSB (Hue, Saturation, Brightness - Matiz) fue creado en 1978 por Alvy Ray Smith.
Es una transformación no lineal de color RGB y se usa para progreciones de color, diferente al modelo HSL.
En la imagen podemos ver el cono del modelo HSV, podemos movernos a través del mismo con un vector de 3 dimensiones de forma:</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/Procedural-texturing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/Procedural-texturing/</guid><description>Procedural texturing # Ejercicio 3 # Las texturas procedimentales son aquellas que se realizan por medio de un una definición matemática. Estas utilizan variables del entorno como el tiempo, la posición del mouse, la posición de los vértices y pixeles entre otras para asignar una textura a una imagen.
Para realizar una textura sobre un objeto es necesario realizar un mapero entra las coordenadas de la figura y el modelo de la figura, siendo este mapeo usualmente lineal.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/UV-Visualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/1.-Texturing/UV-Visualization/</guid><description>UV vizualization # Ejercicio: UV Vizualization # Mediante este ejercicio se puede demostrar la transformación de las coordenadas UV a un rectángulo. Utilizando las posiciones en las coordenadas de textura UV para mapear el color que toma el pixel en la imágen.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/2.-Image-Processing/Image-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/2.-Image-Processing/Image-Processing/</guid><description>Que es el Image Processing # El image Processing es el uso de computadores para procesar imagenes digitales mediante algun algoritmo, en este se permiten un aplio rango de algoritmos para ser aplicados sobre la entrada, ademas puede evitar problemas como el ruido y las distorciones.
En este caso se usan matrices de convolucion o mascaras, se les tiende a llamar matrices de convolucion por el proceso que tienen para empezar se crea una matriz de n*m \[ \begin{vmatrix} 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 1 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 \end{vmatrix}\ \] en este caso de 3x3 esta matriz recorrera la matriz original de la imagen y genera una nueva imagen, en este caso al ser la matriz identidad la imagen generada es la misma, estas imagenes tienden a destacar atributos de la imagen por ejemplo \[ \begin{vmatrix} -1 &amp;amp; -1 &amp;amp; -1\\ -1 &amp;amp; 8 &amp;amp; -1\\-1 &amp;amp; -1 &amp;amp; -1 \end{vmatrix}\] esta matriz se usa para identificar los cambios de relieve de una imagen</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/2.-Image-Processing/magnifierTool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/2.-Image-Processing/magnifierTool/</guid><description> Tool of magnifier # Esta apliación permite utilizar un fragment shader para amplificar el tamaño de la imagen y de un video alreder de un foco.
Instrucciones
Escoja video o imagenen la caja de selección Utilice el desilizador para amuentar o disminuir el tamaño del foco</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/3.-Extra-job/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/3.-Extra-job/</guid><description>Trabajo extra # En este trabajo se presentan dos distintas apliaciones de los shaders el bump mapping y el shadow mapping.
Bump mapping # Esta es una técnica de textura que permite generar relieves sobre una figura, esto se hace modificando las normales de a superficie.
Los bump maps utilizan la iluminación para generar estos tipos de texturas. Por ejemplo, los colores más claros parececen resaltar de las superficies de la textura, mientras que los colores más oscuros parecen estar hundidos dentro de la superficie.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/Shaders/4.-Conclusions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/Shaders/4.-Conclusions/</guid><description>Conclusiones # Los shaders permiten que la computación gráfica sea más rápida y efectiva. Esto se puede ver reflejado en el procesamiento de imágenes, en el cual, para aplicar un filtro, es necesario hacer transformaciones pixel a pixel. En algunas imágenes estos son millones de tareas por realizar. Por tal motivo, paralelizar estos procesos ha permitido que la apliación de filtros sea más rápida, previniendo demoras que puedan entorpecer la experiencia de usuario.</description></item></channel></rss>