[{"id":0,"href":"/showcase/docs/Members/","title":"Members","section":"Docs","content":" Miembros # En esta sección se presentarán los integrantes para la presentación de los trabajos de Computación Visual. Conformados por:\nAndrés Felipe Betancurth Becerra Juan Manuel Correa Lombana Gabriela María García Romero "},{"id":1,"href":"/showcase/docs/Members/Andr%C3%A9s-Felipe-Betancurth-Becerra/","title":"Andrés Felipe Betancurth Becerra","section":"Members","content":" Andrés Felipe Betancurth Becerra # estudiante de decima matricula de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia con lo que es practicamente solo la mitad de avance de mi carrera, me interesa el campo de la inteligencia artificial orientado al maching lerning, las curiosidades y las series.\n"},{"id":2,"href":"/showcase/docs/Members/Gabriela-Mar%C3%ADa-Garc%C3%ADa-Romero/","title":"Gabriela María García Romero","section":"Members","content":" Gabriela María García Romero # Estudiante de octavo semestre de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia. Con interés en temas de modelización e inteligencia artificial. Actualmente se desempeña como representante estudiantil ante el Comité Asesor de la carrea.\nHace parte de los siguientes grupos:\nSemillero Laboratorio de Investigación en Sistemas Inteligentes (LISI) WIE (Women in Engineering) "},{"id":3,"href":"/showcase/docs/Members/Juan-Manuel-Correa-Lombana/","title":"Juan Manuel Correa Lombana","section":"Members","content":" Juan Manuel Correa Lombana # Estudiante de octavo semestre de Ingeniería de Sistemas y Computación en la Universidad Nacional de Colombia. , con 1 año de experiencia en manejo de datos y ciencia de datos. Entre sus proyectos realizados se encuentra:\n6 meses en un proyecto de grafos y optimización de rutas de transporte usando inteligencia artificial 8 meses como analista de datos y ciencia de datos Actualmente llevo 2 meses en ingeniería de datos en el área de arquitectura de bases de datos "},{"id":4,"href":"/showcase/docs/Perlin-Noise/","title":"Perlin Noise","section":"Docs","content":" Ruido de Perlin # El ruido de perlin es una función utilizada en la computación gráfica para crear texturas primitivas. Este fue desarrollado por Ken Perlin en 1983, cuando publicó un artículo llamado An Image Synthesizer.\n¿Qué es ruido? # El ruido es una función pseudo-aleatoria a partir de la cual se pueden generar texturas. Esta se puede representar como una rejilla como la mostrada a continuación:\nEn donde cada vertice tiene asociado un vector\nun vector es un segmento de recta con magnitud y dirección Este es un vector gradiente pseudo aleatorio.\nAsí, el valor del ruido Perlin en el punto se calcula como un producto punto entre el punto entre los vectores de gradiente en los vértices de la grilla y los vectores desde el punto dado a estos vértices.\nPara finalizar, de interpola el resultado con una función. Generalmente se utiliza este polinomio cúbico:\n3x^2 -2x^3 Características # Entre sus características están:\nPseudo-aleatoria Invariante estadísticamente bajo la rotación y translación Tiene un filtro pasa bandas en su frecuencia Esto permite crear superficies a diferentes escalas, y sin perder el control del efecto al rotar y trasladar.\nNaturalidad # El objetivo de Perlin con el diseño del algoritmo era la generación de gráficos que fueran más naturales, es decir, que emulen movimientos y texturas de la naruraleza, obteniendo texturas \u0026ldquo;realistas\u0026rdquo;. Esto lo hace al crear secuencias naturalmente ordenadas y suaves de números pseudoaleatorios.\nEs por esta razón que el ruido de Perlin se ha utilizado para crear representaciones convincentes de nubes, fuego, agua, estrellas, tierra, entre otros.\nReferencias # Michot-Roberto, S., Garcia-Hernández, A., Dopazo-Hilario, S., \u0026amp; Dawson, A. (2021). The spherical primitive and perlin noise method to recreate realistic aggregate shapes. Granular Matter, 23(2), 1-11.\nPerlin, K. (1985). An image synthesizer. ACM Siggraph Computer Graphics, 19(3), 287-296.\nTatarinov, A. (2008). Perlin noise in real-time computer graphics. In GraphiCon (pp. 177-183).\nEn.wikipedia.org. 2022. Perlin noise - Wikipedia. [online] Available at: https://en.wikipedia.org/wiki/Perlin_noise [Accessed 5 April 2022].\n"},{"id":5,"href":"/showcase/docs/Perlin-Noise/Particule/","title":"Particule","section":"Perlin Noise","content":" Movimiento de partículas a través de un campo de perlin noise # En el siguiente frame se puede ver el movimiento con rastro de partículas a través de un campo de perlin noise\nsi jugamos con la rejilla y la dirección de los vectores, se pueden generar texturas o efectos visuales más complejos\nSnow # Grass # Según lo explica Andre Tatarinov en su paper titulado Perlin noise in Real-time Computer Graphics, esto también se puede usar para generar efectos dinámicos volumétricos como fuego, una explosión o humo, esto solo cambiando la dirección y el comportamiento de los vectores asociados a la rejilla.\n"},{"id":6,"href":"/showcase/docs/Perlin-Noise/Terrain/","title":"Terrain","section":"Perlin Noise","content":" Terreno procedural # {{\u0026lt; let terrain = []; function setup() { createCanvas(500, 500, WEBGL); cols = 0;rows = 0; elevacion = 100; scl = 25; vel = 0.05; cambio = scl; crecimiento = 0.07; w = 800; h = 800; cols = w/scl; rows = h/scl; avance = 0; } function stripOfTerrain(){ yoff = avance; xoff = 0; for(x = 0; x \u0026lt; (cols);x++){ terrain[x] = []; } for(y = 0; y \u0026lt; (rows); y++){ xoff = 0; for(x = 0; x \u0026lt; (cols);x++){ terrain[x][y] = map(noise(xoff,yoff),0,1,-elevacion,elevacion); xoff += crecimiento; } yoff += crecimiento; } } function draw() { stripOfTerrain(); cols = w/scl; rows = h/scl; avance -= vel; background(\u0026#39;blue\u0026#39;); stroke(255); rotateX(PI/3); translate(-375,-525); for(y = 0; y \u0026lt; rows; y++){ beginShape(TRIANGLE_STRIP); for(x = 0; x \u0026lt; cols;x++){ fill(10,200,200-terrain[x][y]*10) vertex(x*scl,y*scl,terrain[x][y]); fill(10,255,100-terrain[x][y+1]*10) vertex(x*scl,(y+1)*scl,terrain[x][y+1]); } endShape(); } } \u0026gt;}} All parameters are optional but sketch. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified.\n"},{"id":7,"href":"/showcase/docs/Rendering/1.-Baseline/","title":"1. Baseline","section":"Rendering","content":" Proportionality and symmetry # The key to the illusion realized in the game by forced perception is the proportionality that exists between the field of view and the object. The object grows as much as the field of view. This can be demonstrated by the proportionality theorem for triangles, where the ratio between z\u0026rsquo;/z is equivalent to the ratio between x\u0026rsquo;/x, since they have the same θ the angle of the field of view:\n\\[ \\frac{x\u0026#39;}{x} = \\frac{z\u0026#39;}{z} \\] entonces\n\\[ x\u0026#39; = \\frac{z\u0026#39;*x}{z} \\] The same applies to the y-axis:\n\\[ \\frac{y\u0026#39;}{y} = \\frac{z\u0026#39;}{z} \\] therefore\n\\[ y\u0026#39; = \\frac{z\u0026#39;*y}{z} \\] That is, a change in the distance at which the object is zoomed out will be proportional to the size at which the object grows. And the perception obtained by the camera will be symmetrical.\nCode base # Below is the code in which the phenomenon of forced perspective is explored, this has two scenes, one is the camera and the other is the screen space. Through the following code you can see how the changes made from the camera perspective are reflected in the screen space.\nInstructions\nSelect one of the boxes by pressing one of the numbers from 0 to 9. The box selected will turn red. Use the letter w move the box further from the camera and the letter z to move it closer. Use the slider to adjust the zoom of the camera. On the left you can see how the box remains the same size, while on the right you can see how the object is increasing or decreasing in size in the world. Base superliminal let fbo1, fbo2; let cam1, cam2; let target = 150; let length = 600; let boxes; let box_key; let fovy; const SPEED = 5; function setup() { createCanvas(length, length / 2); // frame buffer object instances (FBOs) fbo1 = createGraphics(width / 2, height, WEBGL); fbo2 = createGraphics(width / 2, height, WEBGL); // FBOs cams cam1 = new Dw.EasyCam(fbo1._renderer, { distance: 200 }); let state1 = cam1.getState(); cam1.attachMouseListeners(this._renderer); cam1.state_reset = state1; // state to use on reset (double-click/tap) cam1.setViewport([0, 0, width / 2, height]); cam2 = new Dw.EasyCam(fbo2._renderer, { rotation: [0.94, 0.33, 0, 0] }); cam2.attachMouseListeners(this._renderer); let state2 = cam2.getState(); cam2.state_reset = state2; // state to use on reset (double-click/tap) cam2.setViewport([width / 2, 0, width / 2, height]); document.oncontextmenu = function () { return false; } // scene colorMode(RGB, 1); let trange = 100; boxes = []; for (let i = 0; i \u0026lt; 10; i++) { boxes.push( { position: createVector((random() * 2 - 1) * trange, (random() * 2 - 1) * trange, (random() * 2 - 1) * trange), size: random() * 25 + 8, color: color(random(), random(), random()) } ); } fovy = createSlider(PI / 12, PI * (11 / 12), PI / 3, PI / 48); fovy.position(10, 10); fovy.style(\u0026#39;width\u0026#39;, \u0026#39;80px\u0026#39;); } function draw() { fbo1.background(200, 125, 115); fbo1.reset(); fbo1.perspective(fovy.value()); fbo1.axes(); fbo1.grid(); scene1(); beginHUD(); image(fbo1, 0, 0); endHUD(); fbo2.background(130); fbo2.reset(); fbo2.axes(); fbo2.grid(); scene2(); fbo2.viewFrustum(fbo1); beginHUD(); image(fbo2, width / 2, 0); endHUD(); } function scene1() { boxes.forEach(box =\u0026gt; { fbo1.push(); fbo1.fill(boxes[box_key] === box ? color(\u0026#39;red\u0026#39;) : box.color); fbo1.translate(box.position); if (boxes[box_key] === box) { if (keyIsPressed \u0026amp;\u0026amp; !mouseIsPressed) { let boxLocation = fbo1.treeLocation([0, 0, 0], { from: fbo1.mMatrix(), to: \u0026#39;WORLD\u0026#39; }); let pixelRatio = fbo1.pixelRatio(boxLocation); box.target ??= box.size / pixelRatio; box.size = box.target * pixelRatio; let eyeLocation = fbo1.treeLocation([0, 0, 0], { from: \u0026#39;EYE\u0026#39;, to: \u0026#39;WORLD\u0026#39; }); box.position.add(p5.Vector.sub(boxLocation, eyeLocation).normalize().mult(key === \u0026#39;w\u0026#39; ? SPEED : -SPEED)); } else { box.target = undefined; } } fbo1.box(box.size); fbo1.pop(); } ); } function scene2() { boxes.forEach(box =\u0026gt; { fbo2.push(); fbo2.fill(boxes[box_key] === box ? color(\u0026#39;red\u0026#39;) : box.color); fbo2.translate(box.position); fbo2.box(box.size); fbo2.pop(); } ); } function keyPressed() { // press [0..9] keys to pick a box and other keys // to unpick, excepting \u0026#39;w\u0026#39; and \u0026#39;z\u0026#39; which are used // to move the box away or closer to eye. if (key !== \u0026#39;w\u0026#39; \u0026amp;\u0026amp; key !== \u0026#39;z\u0026#39;) { box_key = parseInt(key); } } "},{"id":8,"href":"/showcase/docs/Rendering/2.-Pixel-Density/","title":"2. Pixel Density","section":"Rendering","content":" The world and the pixel # Each pixel on the screen represents a quantity of space in the space of the world. The illusion of forced perspective allows to keep the relation that exists between the world and the pixel, that is to say, the amount of world that can be represented in the pixel in the space of the screen, this relation is going to be called density and is used by the function pixelRatio in the code previously seen.\nMove objects away # When the object is moved away from the screen on which it is being displayed, because of the angle of the frustum, the object reduces its size on the screen, however, in the world it still retains its size. This means that each pixel will contain more information about the world, even when the object is the same.\nInstructions The following figure shows a map being represented in a grid which represent the pixels on a screen\nMove the slider above to move the map further or closer to the screen Move the slider below to rotate our perception on the world (Hint: the map and the grid will rotate as well) Change Object\u0026rsquo;s Size # What would happen now if we changed the wor object\u0026rsquo;s size. The answer is that, in the same way that happened in when we changed the distance, the object would appear bigger or smaller on the screen.\nInstructions The following figure shows a map being represented in a grid which represent the pixels on a screen\nMove the slider above to move the map further or closer to the screen Move the slider in the middle to change the map\u0026rsquo;s size Move the slider below to rotate our perception on the world (Hint: the map and the grid will rotate as well) What would happen then if we increase the size while the scene is zoomed out? If we increase the size of the object at the same rate at which the field of view angle increases, what would happen is that the scene generated on the screen would not change, even though the size of the object does change.\nWhat does change is the pixel density, because even though the object is larger in the world, it is the same size on the screen, i.e., in this case the amount stored in each pixel of the world increases.\n"},{"id":9,"href":"/showcase/docs/Rendering/3.-Aplications/","title":"3. Aplications","section":"Rendering","content":" Concept 1 # In the present example an intuitive demonstration of forced perception is made. Two spheres are used which, in perspective, look the same size. However, one of them can be resized in such a way that it changes size in the world, but the camera perceives them as the same size. This happens because of the distance in relation to the camera.\nInstructions\nDo something Concept 2 # In this example we used perspective and size to give 2 different images depending on the point of view, at the beginning the camera is in such a way that it seems that the chicken eats the sphere, but if we change the perspective of camera 1 (left) now we can see the bird inside the sphere, in the second camera (the right side) we can see how nothing has changed but moving the sphere the new perspective becomes real and now the chicken is enclosed in the sphere.\nThis case, like so many others (for example grabbing the moon with the hand taking into account that because of its remoteness it is perceived as small), allowed to move the object without losing the size we see (we can make it actually fit with what we are looking for), this is the basis of the superliminal game.\nInstructions\nDo something Concept 3 # The following is a visual effect achieved by changing the size of a sphere with respect to the plane shown. It shows how the grid fits into the background plane to generate the desired visual effect.\nInstructions\nDo something Results # By means of the present examples it can be seen how changes in size at the same rate as changes in distance result in no apparent change in the camera and screen. However, when implementing the programs the following problems were encountered.\nThe size change is still noticeable in the space of the camera and screen, especially when zoomed in or when the key is pressed interruptedly.\nWhen the object is at very close distances to the camera the object changes its perceived size. Also, when the object crosses the camera, the view of the object is lost and sometimes this can cause problems to the scene, sometimes because the object increases its size disproportionately.\n"},{"id":10,"href":"/showcase/docs/Rendering/4.-Conslusions/","title":"4. Conslusions","section":"Rendering","content":" Conclusions # The Superliminal game is made possible by elements of rendering that occur in computer graphics. It is through the process of the rendering pipeline that it is possible to achieve the effect of forced perception on the players. Even though an object changes in the world, because of its location and size in the world, this change is neither perceivable in the camera nor projectable on the screen.\nHowever, the present work does not consider other attributes of rendering such as shadows and light, which affect the result of the projection of objects according to their depth. If this were the case, the shadows and light of a distant object will be perceived differently by the camera, even if its size is the same in the projection.\nThe triangle proportionality theorem is indispensable for the forced perception effect. It allows to calculate the new coordinates in x and y from the change occurring in z. This happens because in the world the object must keep the same angle with respect to the visual field so that its projection on the screen does not change.\nFinally, through this work it can be noted that pixels are a representation model of the world, i.e., they contain information about the world, such as color. However, sometimes the same pixel contains more information about the world, due to the remoteness of the objects.\nFuture work: # This work puts a starting point for thinking about new visual illusions from the effect of forced perception, which deceives human perception about what they are actually seeing through a screen. One can think of a new era of games in which perception plays an important role and brings an innovative effect, as well as in other applications of rendering such as animation and may also be the film industry.\nAlso, we can think of more intuitive ways of actions to change the size of objects in the world, making them different from pressing the keys w and z, so that the player understands in a better way what he is doing when he changes the size of objects in the world.\nOn the other hand, it is important to understand more clearly the concepts of human vision, in order to understand how attributes such as depth affect the forced perception of objects.\nFinally, all these transformations are done while both the camera and the object are still. A future application would be to realize the illusion of forced perception when there is motion in either of these two spaces.\nReferences # https://blog.playstation.com/2020/06/30/breaking-down-the-tech-behind-superliminals-mind-bending-illusions/\nhttps://findnerd.com/list/view/Computer-Graphics-Different-Spaces/6982/\nhttps://tfetimes.com/wp-content/uploads/2015/04/F.Dunn-I.Parberry-3D-Math-Primer-for-Graphics-and-Game-Development.pdf\nhttps://github.com/VisualComputing/p5.treegl/tree/main/examples/subliminal\n"},{"id":11,"href":"/showcase/docs/Rendering/","title":"Rendering","section":"Docs","content":" Introduction # One of the problems facing computer graphics is how to represent a 3D shape or model on a 2D monitor or screen. This is relevant, because the monitors on which the images are displayed are not continuous spaces like the real world, they are, instead, represented by a grid of pixels, which are a discrete units that can only take one color value.\nThe computer then saves the model of the representation of the scene, which will be displayed on the screen, this process is called rendering, and is a process carried out in animation, video games, 3D modeling, among others.\nIn this paper we will present how the rendering process, known as the graphic pipeline allows a forced perspective of which the game Superliminal is based.\nRendering # When rendering a scene, the main objective is to choose a model or object which will be rendered (it will have its own position, orientation and zoom) and a screen represented in two dimensions, to which the objecy will be translated. The rendering is done by changing different coordinate spaces. These coordinate spaces are:\nModel Space # This is the x,y,z coordinate space under which the object geometry is defined, usually the object is defined by primitives in this space.\nWorld Space # The world is the space under which the whole scene is defined, it has its origin in the center of the scene. It is possible to go from the model space to the world space by means of a model transformation.\nEye Space or Camera # It is the coordinated space with origin in the center of the projection. The camera is the point of view from which the world is seen, it forms a frustum formed from four rays. Every object falling within the spectrum of the four rays will be perceived by the camera, as points in the world are reflected as rays back to the camera.\nZoom # One of the characteristics of the eye space is the zoom. This originates from the fact that the frustum forms angles with the x and y coordinate axes. The larger these angles are, the more of the world space will be percieved in the projection and vice versa.\nThe zoom would allow the camera to increase the space it perceives by increasing its angles, as long as these maintain the proportionality of the image.\nScreen Space # The screen space is a projection from the camera to a 2D space. This is used to project the camera space to a representation on monitors as it is known today on computers.\nGraphic Pipieline # This is a process that describes the steps of rendering an object to its 2D form or, rather, from object space to screen space.\nSuperliminal # Superliminal is a video game from the first person perspective. The plot of the game consists of a player who finds himself trapped in a surreal place called the dream space and must find ways to escape from that place. However, a feature of the dream space mentioned above is that the player can change the size of objects using forced perspective.\nForced perspective # Forced perspective is a phenomenon in which the observer is deceived about the size of an object, i.e. it may appear larger or smaller than it actually is. This occurs because the representation of the scene in the human eye, in this case the camera, perceives the object in a way that appears different from reality.\nIn the specific case of the game, the player has control of the forced perspective, in that he can increase and decrease the size of the objects in the world without changing the size under the perspective of the camera. This is achieved because before the screen space that is generated by the rendering process, the created scene does not change even though in the world the object is changing.\n"}]